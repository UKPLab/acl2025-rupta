<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="https://github.com/UKPLab/acl2025-rupta"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Robust Utility-Preserving Text Anonymization Based on Large Language Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Robust Utility-Preserving Text Anonymization Based on Large Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://gipplab.org/team/tianyu-yang/" target="_blank">Tianyu Yang</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://www.xiaodanzhu.com/" target="_blank">Xiaodan Zhu</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.informatik.tu-darmstadt.de/ukp/ukp_home/head_ukp/index.en.jsp" target="_blank">Iryna Gurevych</a><sup>1</sup>,</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Ubiquitous Knowledge Processing Lab (UKP Lab), Department of Computer Science and Hessian Center for AI (hessian.AI), Technical University of Darmstadt, Germany <br><sup>2</sup>Department of Electrical and Computer Engineering & Ingenuity Labs Research Institute, Queen’s University, Canada<br>Accepted by ACL 2025 Main Conference</span>
                    
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2407.11770" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/UKPLab/acl2025-rupta" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2407.11770" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Anonymizing text that contains sensitive information is crucial for a wide range of applications. Existing techniques face the emerging challenges of the re-identification ability of large language models (LLMs), which have shown advanced capability in memorizing detailed information and reasoning over dispersed pieces of patterns to draw conclusions. When defending against LLM-based re-identification, anonymization could jeopardize the utility of the resulting anonymized data in downstream tasks. In general, the interaction between anonymization and data utility requires a deeper understanding within the context of LLMs. In this paper, we propose a framework composed of three key LLM-based components: a privacy evaluator, a utility evaluator, and an optimization component, which work collaboratively to perform anonymization. Extensive experiments demonstrate that the proposed model outperforms existing baselines, showing robustness in reducing the risk of re-identification while preserving greater data utility in downstream tasks. We provide detailed studies on these core modules. To consider large-scale and real-time applications, we investigate the distillation of the anonymization capabilities into lightweight models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->
      
<!-- Intro -->
<section class="section">
    <div class="container is-max-desktop">
        <h3 class="title is-3 has-text-centered">
            Two Challenges Faced by The Text Anonymization Task
        </h3>
        <div class="columns has-text-left">
            <div class="column is-half column-padding has-text-left">
                <div class="content">
                    <p>
                        <ul style="font-family: Arial, sans-serif; line-height: 1.6; font-size: 16px;">
  <li style="color: #d35400;">
     <strong>Privacy Safety:</strong> current text anonymization techniques are vulnerable to disclosure threats from increasingly sophisticated LLMs. Many recent studies have demonstrated that such models can re-identify private information, even from texts anonymized by advanced methods
  </li>
  <li style="color: #1f4e79;">
    <strong>Utility For Downstream Tasks:</strong> existing studies only evaluate the utility of the anonymized text for downstream tasks after the anonymization process, thus they can not adapt the anonymization strategy to balance the privacy-utility tradeoff dynamically. Besides, existing studies mainly evaluate the utility mainly from the perspective of text quality, lacking investigation of the impact on downstream tasks.
  </li>
</ul>

                    </p>
                </div>
            </div>
            <div class="column is-half column-padding">
                <figure>
                    <img src="static/images/examples3.jpg" alt="Descriptive text for the figure">
                </figure>
            </div>
        </div>
    </div>
</section>
<!-- End intro -->


<!-- Data collection -->
<section class="section">
    <div class="container is-max-desktop">
        <h3 class="title is-3 has-text-centered">
            Our Contributions
        </h3>

          <div class="container is-max-desktop mb-6">
            <h4 class="title is-4 has-text-left mb-6">
                 RUPTA: A multi-objective framework for text anonymization
            </h4>
                    <div class="content has-text-justified">
          <p>
            This paper proposes to model the text anonymization task with the mult-objective problem where both privacy and utility are optimized during the anonymization process. Advanced LLMs are employed to act as the evaluator and black-box optimizer. Specefically, a novel framework, <strong>RUPTA</strong>, is presented, where a privacy evaluator, a utility evaluator, and an optimizer are integrated to effectively anonymize text, ensuring reduced risk of re-identification while maintaining utility for downstream tasks.
          </p>
        </div>
            <figure class="image mb-6">
                <img src="static/images/LLM_ann_fra_4.jpg" alt="Descriptive text for the figure"
                     style="width: 100%; height: auto;">
            </figure>
        </div>
        <div class="container is-max-desktop mb-6">
            <h4 class="title is-4 has-text-left mb-6">
                Db-bio dataset
            </h4>
            <div class="content has-text-justified">
          <p>
            Previous anonymization studies have been conducted on celebrity data available in Wikipedia. Inspired by that, we sampled celebrity biographies from the DBpedia Classes dataset to build a new <strong>DB-bio</strong> dataset for our study and future research, where we used the category labels of each celebrity in the DBpedia Classes as the occupation classification label. Anonymization results based on the RUPTA framework by GPT-4 are released together with the dataset to facilitate future studies. 
          </p>
        </div>
        </div>
    </div>
</section>
<!-- End data collection -->



<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/ACL 2025_main-4239_poster.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{yang2024robust,
  title={Robust Utility-Preserving Text Anonymization Based on Large Language Models},
  author={Yang, Tianyu and Zhu, Xiaodan and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2407.11770},
  year={2024}
}
</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
